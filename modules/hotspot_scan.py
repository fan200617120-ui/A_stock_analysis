# modules/hotspot_scan.py
import streamlit as st
import pandas as pd
import plotly.graph_objects as go
import plotly.express as px
import numpy as np
from datetime import datetime, timedelta
from modules import data_processing

# ==================== ç¬¬ä¸€é˜¶æ®µï¼šåŸºç¡€è§£æå’Œå…±ç°çŸ©é˜µ ====================

def parse_hot_limit_enhanced(s: str):
    """å¢å¼ºè§£æï¼šæŠŠ 'å…ƒå™¨ä»¶10+6' æ‹†æˆ ('å…ƒå™¨ä»¶', 10, 6)"""
    items = []
    try:
        for item in s.split("\\"):
            item = item.strip()
            if not item:
                continue
                
            if "+" in item:
                # åˆ†ç¦»åç§°å’Œæ•°å­—éƒ¨åˆ†
                name_part = item.rsplit("+", 1)[0]
                num_part = item.rsplit("+", 1)[1]
                
                # æå–åç§°ï¼ˆå»é™¤æœ«å°¾æ•°å­—ï¼‰
                import re
                name = re.sub(r'\d+$', '', name_part).strip()
                
                # æå–æ¶¨åœæ•°å’Œæ¶¨å¹…å¤§äº10%æ•°
                limit_up_match = re.findall(r'\d+', name_part)
                limit_up = int(limit_up_match[-1]) if limit_up_match else 0
                rise_over_10 = int(num_part) if num_part.isdigit() else 0
                
                items.append((name, limit_up, rise_over_10))
            else:
                # æ²¡æœ‰+çš„æƒ…å†µï¼Œå°è¯•æå–åç§°å’Œæ•°å­—
                import re
                matches = re.findall(r'(\D+)(\d+)', item)
                if matches:
                    name = matches[0][0].strip()
                    limit_up = int(matches[0][1])
                    items.append((name, limit_up, 0))
                else:
                    items.append((item.strip(), 1, 0))
    except Exception as e:
        st.error(f"è§£æçƒ­ç‚¹æ•°æ®æ—¶å‡ºé”™: {str(e)}")
        return [("è§£æé”™è¯¯", 1, 0)]
    
    return items

def create_cooccurrence_heatmap(industry_str: str, concept_str: str, method="combined_strength"):
    """åˆ›å»ºåŸºäºå…±ç°åŸç†çš„çƒ­åŠ›å›¾"""
    try:
        ind_list = parse_hot_limit_enhanced(industry_str or "")
        conc_list = parse_hot_limit_enhanced(concept_str or "")
        
        if not ind_list or not conc_list:
            return None
            
        # æ„å»ºå…±ç°çŸ©é˜µ
        heat_data = []
        hover_text = []
        
        for industry_name, ind_limit, ind_rise in ind_list:
            row = []
            hover_row = []
            for concept_name, conc_limit, conc_rise in conc_list:
                if method == "geometric_mean":
                    # å‡ ä½•å¹³å‡ - æ›´åˆç†çš„å…³è”åº¦è®¡ç®—
                    value = (ind_limit * conc_limit) ** 0.5
                elif method == "min_normalized":
                    # æœ€å°å€¼å½’ä¸€åŒ–
                    value = min(ind_limit, conc_limit)
                elif method == "combined_strength":
                    # ç»¼åˆå¼ºåº¦ï¼šè€ƒè™‘æ¶¨åœæ•°å’Œæ¶¨å¹…å¤§äº10%çš„æ•°é‡
                    total_ind = ind_limit + ind_rise * 0.5  # æ¶¨å¹…å¤§äº10%ç»™äºˆ0.5çš„æƒé‡
                    total_conc = conc_limit + conc_rise * 0.5
                    value = (total_ind * total_conc) ** 0.5
                elif method == "jaccard_similarity":
                    # è¿‘ä¼¼Jaccardç›¸ä¼¼åº¦
                    union = ind_limit + conc_limit - min(ind_limit, conc_limit)
                    value = min(ind_limit, conc_limit) / union if union > 0 else 0
                else:
                    # é»˜è®¤ä½¿ç”¨ç»¼åˆå¼ºåº¦
                    total_ind = ind_limit + ind_rise * 0.5
                    total_conc = conc_limit + conc_rise * 0.5
                    value = (total_ind * total_conc) ** 0.5
                
                row.append(round(value, 2))
                hover_row.append(
                    f"è¡Œä¸š: {industry_name}<br>" +
                    f"æ¦‚å¿µ: {concept_name}<br>" +
                    f"è¡Œä¸šæ¶¨åœ: {ind_limit}+{ind_rise}<br>" +
                    f"æ¦‚å¿µæ¶¨åœ: {conc_limit}+{conc_rise}<br>" +
                    f"å…±ç°å¼ºåº¦: {value:.2f}"
                )
            
            heat_data.append(row)
            hover_text.append(hover_row)
        
        # åˆ›å»ºDataFrame
        heat_df = pd.DataFrame(
            heat_data,
            index=[i[0] for i in ind_list],
            columns=[c[0] for c in conc_list]
        )
        
        # åˆ›å»ºçƒ­åŠ›å›¾
        fig = go.Figure(go.Heatmap(
            z=heat_df.values,
            x=heat_df.columns,
            y=heat_df.index,
            colorscale="Reds",
            text=heat_df.values,
            texttemplate="%{z:.1f}",
            customdata=hover_text,
            hovertemplate="%{customdata}<extra></extra>"
        ))
        
        method_names = {
            "geometric_mean": "å‡ ä½•å¹³å‡",
            "min_normalized": "æœ€å°å€¼å½’ä¸€åŒ–", 
            "combined_strength": "ç»¼åˆå¼ºåº¦",
            "jaccard_similarity": "ç›¸ä¼¼åº¦"
        }
        
        fig.update_layout(
            height=400,
            margin=dict(l=50, r=50, t=50, b=50),
            xaxis_title="æ¦‚å¿µ",
            yaxis_title="è¡Œä¸š",
            xaxis_tickangle=-45,
            title=f"æ¶¨åœæ¦œçƒ­åŠ›å›¾ - å…±ç°çŸ©é˜µåˆ†æ ({method_names.get(method, 'ç»¼åˆå¼ºåº¦')})"
        )
        
        return fig
    except Exception as e:
        st.error(f"åˆ›å»ºå…±ç°çƒ­åŠ›å›¾æ—¶å‡ºé”™: {str(e)}")
        return None

def create_rank_cooccurrence_heatmap(industry_str: str, concept_str: str, title: str = "æ¶¨å¹…æ¦œçƒ­åŠ›å›¾"):
    """åˆ›å»ºåŸºäºæ’åçš„å…±ç°çƒ­åŠ›å›¾ï¼ˆç”¨äºæ¶¨å¹…æ¦œï¼‰"""
    try:
        # è§£æè¡Œä¸šå’Œæ¦‚å¿µåˆ—è¡¨ï¼ˆæ¶¨å¹…æ¦œåªæœ‰åç§°ï¼Œæ²¡æœ‰æ•°å­—ï¼‰
        industries = [item.strip() for item in industry_str.split('\\') if item.strip()]
        concepts = [item.strip() for item in concept_str.split('\\') if item.strip()]
        
        if not industries or not concepts:
            return None
        
        # åˆ›å»ºåŸºäºæ’åçš„å…±ç°çŸ©é˜µ
        heat_data = []
        hover_text = []
        
        for i, industry in enumerate(industries):
            row = []
            hover_row = []
            for j, concept in enumerate(concepts):
                # ä½¿ç”¨æ’åè¡°å‡å› å­ï¼šæ’åè¶Šé å‰ï¼Œå…³è”åº¦è¶Šé«˜
                industry_rank_factor = 1.0 / (i + 1)  # ç¬¬1å=1.0, ç¬¬2å=0.5, ç¬¬3å=0.33...
                concept_rank_factor = 1.0 / (j + 1)
                
                # å…±ç°å¼ºåº¦ = è¡Œä¸šæ’åå› å­ Ã— æ¦‚å¿µæ’åå› å­
                cooccurrence_strength = industry_rank_factor * concept_rank_factor * 10
                
                row.append(round(cooccurrence_strength, 2))
                hover_row.append(
                    f"è¡Œä¸š: {industry} (æ’å{i+1})<br>" +
                    f"æ¦‚å¿µ: {concept} (æ’å{j+1})<br>" +
                    f"å…±ç°å¼ºåº¦: {cooccurrence_strength:.2f}"
                )
            
            heat_data.append(row)
            hover_text.append(hover_row)
        
        # åˆ›å»ºçƒ­åŠ›å›¾
        fig = go.Figure(go.Heatmap(
            z=heat_data,
            x=concepts,
            y=industries,
            colorscale="Reds",
            text=[[f"{cooccurrence_strength:.1f}" for cooccurrence_strength in row] for row in heat_data],
            texttemplate="%{text}",
            customdata=hover_text,
            hovertemplate="%{customdata}<extra></extra>"
        ))
        
        fig.update_layout(
            height=400,
            margin=dict(l=50, r=50, t=50, b=50),
            xaxis_title="æ¦‚å¿µ",
            yaxis_title="è¡Œä¸š",
            xaxis_tickangle=-45,
            title=f"{title} - æ’åå…±ç°åˆ†æ"
        )
        
        return fig
    except Exception as e:
        st.error(f"åˆ›å»ºæ’åå…±ç°çƒ­åŠ›å›¾æ—¶å‡ºé”™: {str(e)}")
        return None

# ==================== ç¬¬äºŒé˜¶æ®µï¼šæ—¶é—´åºåˆ—åˆ†æ ====================

def temporal_cooccurrence_analysis(recent_df, min_strength=2.0, min_days=2):
    """æ—¶é—´åºåˆ—å…±ç°åˆ†æ - å‘ç°æŒç»­æ€§çƒ­ç‚¹"""
    
    # æ”¶é›†æ‰€æœ‰äº¤æ˜“æ—¥çš„æ•°æ®
    temporal_data = []
    
    for _, row in recent_df.iterrows():
        date = row['æ—¥æœŸ'] if 'æ—¥æœŸ' in row else "æœªçŸ¥æ—¥æœŸ"
        
        # è§£æå½“æ—¥çš„è¡Œä¸šå’Œæ¦‚å¿µæ¶¨åœæ•°æ®
        if pd.notna(row.get('è¡Œä¸šæ¶¨åœæ¦œ')) and pd.notna(row.get('æ¦‚å¿µæ¶¨åœæ¦œ')):
            industries = parse_hot_limit_enhanced(str(row['è¡Œä¸šæ¶¨åœæ¦œ']))
            concepts = parse_hot_limit_enhanced(str(row['æ¦‚å¿µæ¶¨åœæ¦œ']))
            
            # è®¡ç®—å½“æ—¥çš„å…±ç°å¼ºåº¦
            for industry_name, ind_limit, ind_rise in industries:
                for concept_name, conc_limit, conc_rise in concepts:
                    # è®¡ç®—ç»¼åˆå¼ºåº¦
                    total_ind = ind_limit + ind_rise * 0.5
                    total_conc = conc_limit + conc_rise * 0.5
                    strength = (total_ind * total_conc) ** 0.5
                    
                    if strength >= min_strength:
                        temporal_data.append({
                            'date': date,
                            'industry': industry_name,
                            'concept': concept_name,
                            'industry_limit': ind_limit,
                            'industry_rise': ind_rise,
                            'concept_limit': conc_limit,
                            'concept_rise': conc_rise,
                            'strength': round(strength, 2),
                            'industry_concept': f"{industry_name}Ã—{concept_name}"
                        })
    
    if not temporal_data:
        return None, None, None, None
    
    # åˆ›å»ºæ—¶é—´åºåˆ—DataFrame
    temporal_df = pd.DataFrame(temporal_data)
    
    # åˆ†ææŒç»­æ€§çƒ­ç‚¹
    persistence_analysis = analyze_persistence(temporal_df, min_days)
    
    # ç”Ÿæˆæ—¶é—´åºåˆ—å¯è§†åŒ–
    timeline_fig = create_timeline_chart(temporal_df)
    persistence_fig = create_persistence_chart(persistence_analysis)
    heatmap_fig = create_temporal_heatmap(temporal_df)
    
    return temporal_df, timeline_fig, persistence_fig, heatmap_fig

def analyze_persistence(temporal_df, min_days=2):
    """åˆ†æçƒ­ç‚¹æŒç»­æ€§"""
    
    # è®¡ç®—æ¯ä¸ªè¡Œä¸š-æ¦‚å¿µç»„åˆçš„å‡ºç°å¤©æ•°
    persistence_stats = temporal_df.groupby('industry_concept').agg({
        'date': 'nunique',
        'strength': ['mean', 'max', 'min'],
        'industry': 'first',
        'concept': 'first'
    }).round(2)
    
    # æ‰å¹³åŒ–åˆ—å
    persistence_stats.columns = ['days_count', 'strength_mean', 'strength_max', 'strength_min', 'industry', 'concept']
    persistence_stats = persistence_stats.reset_index()
    
    # è¿‡æ»¤å‡ºæŒç»­å‡ºç°çš„çƒ­ç‚¹
    persistent_hotspots = persistence_stats[persistence_stats['days_count'] >= min_days].copy()
    persistent_hotspots = persistent_hotspots.sort_values(['days_count', 'strength_mean'], ascending=[False, False])
    
    return persistent_hotspots

def create_timeline_chart(temporal_df):
    """åˆ›å»ºæ—¶é—´åºåˆ—è¶‹åŠ¿å›¾"""
    
    # é€‰æ‹©å¼ºåº¦æœ€é«˜çš„å‡ ä¸ªç»„åˆæ¥æ˜¾ç¤ºï¼Œé¿å…è¿‡äºæ‹¥æŒ¤
    top_combinations = temporal_df.groupby('industry_concept')['strength'].max().nlargest(8).index
    
    filtered_df = temporal_df[temporal_df['industry_concept'].isin(top_combinations)]
    
    fig = px.line(
        filtered_df, 
        x='date', 
        y='strength', 
        color='industry_concept',
        title='ğŸ“ˆ çƒ­ç‚¹ç»„åˆå¼ºåº¦æ—¶é—´åºåˆ—',
        labels={'strength': 'å…±ç°å¼ºåº¦', 'date': 'æ—¥æœŸ', 'industry_concept': 'è¡Œä¸šÃ—æ¦‚å¿µ'}
    )
    
    fig.update_layout(
        height=400,
        xaxis_title="æ—¥æœŸ",
        yaxis_title="å…±ç°å¼ºåº¦",
        legend_title="çƒ­ç‚¹ç»„åˆ",
        hovermode='x unified'
    )
    
    return fig

def create_persistence_chart(persistence_df):
    """åˆ›å»ºæŒç»­æ€§çƒ­ç‚¹å›¾è¡¨"""
    
    if persistence_df.empty:
        return None
    
    # å–å‰15ä¸ªæŒç»­æ€§çƒ­ç‚¹
    top_persistent = persistence_df.head(15)
    
    fig = px.bar(
        top_persistent,
        x='strength_mean',
        y='industry_concept',
        orientation='h',
        title='ğŸ”¥ æŒç»­æ€§çƒ­ç‚¹æ’è¡Œæ¦œ',
        labels={'strength_mean': 'å¹³å‡å…±ç°å¼ºåº¦', 'industry_concept': 'è¡Œä¸šÃ—æ¦‚å¿µç»„åˆ'},
        color='days_count',
        color_continuous_scale='Reds'
    )
    
    fig.update_layout(
        height=500,
        xaxis_title="å¹³å‡å…±ç°å¼ºåº¦",
        yaxis_title="",
        showlegend=False
    )
    
    # æ·»åŠ å¤©æ•°æ ‡æ³¨
    for i, row in enumerate(top_persistent.itertuples()):
        fig.add_annotation(
            x=row.strength_mean + 0.1,
            y=row.industry_concept,
            text=f"{row.days_count}å¤©",
            showarrow=False,
            font=dict(size=10)
        )
    
    return fig

def create_temporal_heatmap(temporal_df):
    """åˆ›å»ºæ—¶é—´åºåˆ—çƒ­åŠ›å›¾"""
    
    # åˆ›å»ºæ•°æ®é€è§†è¡¨
    pivot_data = temporal_df.pivot_table(
        index='industry_concept',
        columns='date',
        values='strength',
        aggfunc='mean'
    ).fillna(0)
    
    # é€‰æ‹©å‡ºç°å¤©æ•°æœ€å¤šçš„ç»„åˆ
    if len(pivot_data) > 20:
        # æŒ‰å‡ºç°å¤©æ•°æ’åºï¼ˆéç©ºåˆ—æ•°ï¼‰
        pivot_data['days_count'] = (pivot_data > 0).sum(axis=1)
        pivot_data = pivot_data.nlargest(20, 'days_count')
        pivot_data = pivot_data.drop('days_count', axis=1)
    
    if pivot_data.empty:
        return None
    
    fig = go.Figure(go.Heatmap(
        z=pivot_data.values,
        x=pivot_data.columns.astype(str),
        y=pivot_data.index,
        colorscale="Reds",
        hovertemplate="<b>%{y}</b><br>æ—¥æœŸ: %{x}<br>å¼ºåº¦: %{z:.2f}<extra></extra>"
    ))
    
    fig.update_layout(
        height=600,
        title="ğŸ“… çƒ­ç‚¹ç»„åˆæ—¶é—´åºåˆ—çƒ­åŠ›å›¾",
        xaxis_title="æ—¥æœŸ",
        yaxis_title="è¡Œä¸šÃ—æ¦‚å¿µç»„åˆ",
        xaxis_tickangle=-45
    )
    
    return fig

def create_sector_rotation_chart(temporal_df):
    """åˆ›å»ºæ¿å—è½®åŠ¨åˆ†æå›¾"""
    
    # åˆ†æè¡Œä¸šè½®åŠ¨
    industry_rotation = temporal_df.groupby(['date', 'industry']).agg({
        'strength': 'sum'
    }).reset_index()
    
    # é€‰æ‹©æ´»è·ƒè¡Œä¸š
    active_industries = industry_rotation.groupby('industry')['strength'].sum().nlargest(10).index
    filtered_industry = industry_rotation[industry_rotation['industry'].isin(active_industries)]
    
    fig_industry = px.line(
        filtered_industry,
        x='date',
        y='strength',
        color='industry',
        title='ğŸ”„ è¡Œä¸šè½®åŠ¨åˆ†æ',
        labels={'strength': 'è¡Œä¸šæ€»å¼ºåº¦', 'date': 'æ—¥æœŸ', 'industry': 'è¡Œä¸š'}
    )
    
    fig_industry.update_layout(height=400)
    
    # åˆ†ææ¦‚å¿µè½®åŠ¨
    concept_rotation = temporal_df.groupby(['date', 'concept']).agg({
        'strength': 'sum'
    }).reset_index()
    
    active_concepts = concept_rotation.groupby('concept')['strength'].sum().nlargest(10).index
    filtered_concept = concept_rotation[concept_rotation['concept'].isin(active_concepts)]
    
    fig_concept = px.line(
        filtered_concept,
        x='date',
        y='strength',
        color='concept',
        title='ğŸ”„ æ¦‚å¿µè½®åŠ¨åˆ†æ',
        labels={'strength': 'æ¦‚å¿µæ€»å¼ºåº¦', 'date': 'æ—¥æœŸ', 'concept': 'æ¦‚å¿µ'}
    )
    
    fig_concept.update_layout(height=400)
    
    return fig_industry, fig_concept

# ==================== ä¸»ç•Œé¢å‡½æ•° ====================

def show_daily_analysis(recent_df):
    """æ˜¾ç¤ºå•æ—¥çƒ­ç‚¹åˆ†æï¼ˆç¬¬ä¸€é˜¶æ®µçš„åŠŸèƒ½ï¼‰"""
    
    st.markdown(
        '<div style="color: #ff6b00 !important; font-size: 16px; font-weight: bold; margin: 20px 0 10px 0;">ğŸ“‹ è¯¦ç»†çƒ­ç‚¹æ’è¡Œ</div>',
        unsafe_allow_html=True
    )

    # åˆ›å»ºæ ‡ç­¾é¡µæ˜¾ç¤ºä¸åŒæ—¥æœŸçš„çƒ­ç‚¹
    if len(recent_df) > 0:
        tab_titles = []
        for _, row in recent_df.iterrows():
            if 'æ—¥æœŸ' in row:
                date_val = row['æ—¥æœŸ']
                if hasattr(date_val, 'strftime'):
                    tab_titles.append(f"ğŸ“… {date_val.strftime('%m-%d')}")
                else:
                    tab_titles.append(f"ğŸ“… {str(date_val)[5:10]}")
            else:
                tab_titles.append(f"ğŸ“… ç¬¬{_+1}å¤©")

        date_tabs = st.tabs(tab_titles)

        for tab_idx, (_, row) in enumerate(zip(date_tabs, recent_df.iterrows())):
            _, row_data = row
            with date_tabs[tab_idx]:
                # æ˜¾ç¤ºæ—¥æœŸ
                if 'æ—¥æœŸ' in row_data:
                    date_str = row_data['æ—¥æœŸ'].strftime('%Y-%m-%d') if hasattr(row_data['æ—¥æœŸ'], 'strftime') else str(row_data['æ—¥æœŸ'])
                    st.markdown(f"#### ğŸ—“ï¸ {date_str} å¸‚åœºçƒ­ç‚¹åˆ†å¸ƒ")
                else:
                    st.markdown(f"#### ğŸ—“ï¸ äº¤æ˜“æ—¥ {tab_idx+1} å¸‚åœºçƒ­ç‚¹åˆ†å¸ƒ")

                # å››åˆ—å¸ƒå±€æ˜¾ç¤ºå„ç±»æ¦œå•
                col1, col2, col3, col4 = st.columns(4)

                # è¡Œä¸šæ¶¨å¹…æ¦œ
                with col1:
                    st.markdown("**ğŸ† è¡Œä¸šæ¶¨å¹…æ¦œ**")
                    if pd.notna(row_data.get('è¡Œä¸šæ¶¨å¹…æ¦œ')):
                        industries = str(row_data['è¡Œä¸šæ¶¨å¹…æ¦œ']).split('\\')
                        for i, industry in enumerate(industries[:8]):
                            if industry.strip():
                                st.markdown(f"<div style='color: #ff6b00; font-size: 14px;'>{i+1}. {industry.strip()}</div>", 
                                          unsafe_allow_html=True)
                    else:
                        st.markdown("<div style='color: #ff6b00;'>æš‚æ— æ•°æ®</div>", unsafe_allow_html=True)

                # æ¦‚å¿µæ¶¨å¹…æ¦œ
                with col2:
                    st.markdown("**ğŸ¯ æ¦‚å¿µæ¶¨å¹…æ¦œ**")
                    if pd.notna(row_data.get('æ¦‚å¿µæ¶¨å¹…æ¦œ')):
                        concepts = str(row_data['æ¦‚å¿µæ¶¨å¹…æ¦œ']).split('\\')
                        for i, concept in enumerate(concepts[:8]):
                            if concept.strip():
                                st.markdown(f"<div style='color: #ff6b00; font-size: 14px;'>{i+1}. {concept.strip()}</div>", 
                                          unsafe_allow_html=True)
                    else:
                        st.markdown("<div style='color: #ff6b00;'>æš‚æ— æ•°æ®</div>", unsafe_allow_html=True)

                # è¡Œä¸šæ¶¨åœæ¦œï¼ˆå¸¦è¯¦ç»†æ•°æ®ï¼‰
                with col3:
                    st.markdown("**ğŸ”¥ è¡Œä¸šæ¶¨åœæ¦œ**")
                    if pd.notna(row_data.get('è¡Œä¸šæ¶¨åœæ¦œ')):
                        limit_industries = str(row_data['è¡Œä¸šæ¶¨åœæ¦œ']).split('\\')
                        for i, industry in enumerate(limit_industries[:8]):
                            if industry.strip():
                                industry_data = parse_hot_limit_enhanced(industry)
                                if industry_data:
                                    name, limit_up, rise_over_10 = industry_data[0]
                                    display_text = f"{name} ({limit_up}+{rise_over_10})"
                                else:
                                    display_text = industry.strip()
                                st.markdown(f"<div style='color: #ff6b00; font-size: 14px;'>{i+1}. {display_text}</div>", 
                                          unsafe_allow_html=True)
                    else:
                        st.markdown("<div style='color: #ff6b00;'>æš‚æ— æ•°æ®</div>", unsafe_allow_html=True)

                # æ¦‚å¿µæ¶¨åœæ¦œï¼ˆå¸¦è¯¦ç»†æ•°æ®ï¼‰
                with col4:
                    st.markdown("**ğŸ’¥ æ¦‚å¿µæ¶¨åœæ¦œ**")
                    if pd.notna(row_data.get('æ¦‚å¿µæ¶¨åœæ¦œ')):
                        limit_concepts = str(row_data['æ¦‚å¿µæ¶¨åœæ¦œ']).split('\\')
                        for i, concept in enumerate(limit_concepts[:8]):
                            if concept.strip():
                                concept_data = parse_hot_limit_enhanced(concept)
                                if concept_data:
                                    name, limit_up, rise_over_10 = concept_data[0]
                                    display_text = f"{name} ({limit_up}+{rise_over_10})"
                                else:
                                    display_text = concept.strip()
                                st.markdown(f"<div style='color: #ff6b00; font-size: 14px;'>{i+1}. {display_text}</div>", 
                                          unsafe_allow_html=True)
                    else:
                        st.markdown("<div style='color: #ff6b00;'>æš‚æ— æ•°æ®</div>", unsafe_allow_html=True)

            
                # çƒ­åŠ›å›¾éƒ¨åˆ†
                st.markdown("---")
                st.markdown("#### ğŸ”¥ çƒ­ç‚¹å…³è”åˆ†æ - å…±ç°çŸ©é˜µ")
                
                # å…±ç°ç®—æ³•é€‰æ‹©
                col_method1, col_method2 = st.columns(2)
                with col_method1:
                    rank_method = st.selectbox(
                        "æ¶¨å¹…æ¦œç®—æ³•", 
                        ["æ’åè¡°å‡", "å‡ ä½•å¹³å‡", "ç»¼åˆå¼ºåº¦"],
                        index=0,
                        key=f"rank_method_{tab_idx}"
                    )
                with col_method2:
                    limit_method = st.selectbox(
                        "æ¶¨åœæ¦œç®—æ³•",
                        ["ç»¼åˆå¼ºåº¦", "å‡ ä½•å¹³å‡", "æœ€å°å€¼å½’ä¸€åŒ–", "ç›¸ä¼¼åº¦"],
                        index=0,
                        key=f"limit_method_{tab_idx}"
                    )

                # ä¸¤åˆ—çƒ­åŠ›å›¾å¸ƒå±€
                col1, col2 = st.columns(2)

                # æ¶¨å¹…æ¦œçƒ­åŠ›å›¾
                with col1:
                    if pd.notna(row_data.get('è¡Œä¸šæ¶¨å¹…æ¦œ')) and pd.notna(row_data.get('æ¦‚å¿µæ¶¨å¹…æ¦œ')):
                        if rank_method == "æ’åè¡°å‡":
                            fig_rank = create_rank_cooccurrence_heatmap(
                                str(row_data['è¡Œä¸šæ¶¨å¹…æ¦œ']),
                                str(row_data['æ¦‚å¿µæ¶¨å¹…æ¦œ']),
                                title="æ¶¨å¹…æ¦œçƒ­åŠ›å›¾"
                            )
                        else:
                            fig_rank = create_cooccurrence_heatmap(
                                str(row_data['è¡Œä¸šæ¶¨å¹…æ¦œ']),
                                str(row_data['æ¦‚å¿µæ¶¨å¹…æ¦œ']),
                                method=rank_method.lower().replace(" ", "_")
                            )
                        
                        if fig_rank:
                            st.plotly_chart(fig_rank, use_container_width=True)
                    else:
                        st.markdown("<div style='color: #ff6b00;'>æ¶¨å¹…æ¦œæ•°æ®ä¸å®Œæ•´</div>", unsafe_allow_html=True)

                # æ¶¨åœæ¦œçƒ­åŠ›å›¾
                with col2:
                    if pd.notna(row_data.get('è¡Œä¸šæ¶¨åœæ¦œ')) and pd.notna(row_data.get('æ¦‚å¿µæ¶¨åœæ¦œ')):
                        fig_limit = create_cooccurrence_heatmap(
                            str(row_data['è¡Œä¸šæ¶¨åœæ¦œ']),
                            str(row_data['æ¦‚å¿µæ¶¨åœæ¦œ']),
                            method=limit_method.lower().replace(" ", "_")
                        )
                        if fig_limit:
                            st.plotly_chart(fig_limit, use_container_width=True)
                    else:
                        st.markdown("<div style='color: #ff6b00;'>æ¶¨åœæ¦œæ•°æ®ä¸å®Œæ•´</div>", unsafe_allow_html=True)

    else:
        st.markdown("<div style='color: #ff6b00;'>æ²¡æœ‰è¶³å¤Ÿçš„æ•°æ®æ˜¾ç¤ºçƒ­ç‚¹æ‰«æ</div>", unsafe_allow_html=True)

def show_temporal_analysis(recent_df, display_days):
    """æ˜¾ç¤ºæ—¶é—´åºåˆ—åˆ†æ"""
    
    st.markdown(
        '<div style="color: #ff6b00 !important; font-size: 16px; font-weight: bold; margin: 20px 0 10px 0;">ğŸ“ˆ æ—¶é—´åºåˆ—å…±ç°åˆ†æ</div>',
        unsafe_allow_html=True
    )
    
    # å‚æ•°è®¾ç½®
    col1, col2, col3 = st.columns(3)
    with col1:
        min_strength = st.slider("æœ€å°å¼ºåº¦é˜ˆå€¼", 0.0, 10.0, 2.0, 0.5, key="min_strength")
    with col2:
        min_days = st.slider("æœ€å°æŒç»­å¤©æ•°", 1, display_days, 2, 1, key="min_days")
    with col3:
        analysis_type = st.selectbox(
            "åˆ†æç±»å‹",
            ["æŒç»­æ€§çƒ­ç‚¹", "è½®åŠ¨åˆ†æ", "æ—¶é—´åºåˆ—çƒ­åŠ›å›¾"],
            key="analysis_type"
        )
    
    # æ‰§è¡Œæ—¶é—´åºåˆ—åˆ†æ
    with st.spinner("è¿›è¡Œæ—¶é—´åºåˆ—å…±ç°åˆ†æ..."):
        temporal_df, timeline_fig, persistence_fig, heatmap_fig = temporal_cooccurrence_analysis(
            recent_df, min_strength, min_days
        )
    
    if temporal_df is None:
        st.warning("æ²¡æœ‰æ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„æ—¶é—´åºåˆ—æ•°æ®ï¼Œè¯·è°ƒæ•´ç­›é€‰å‚æ•°ã€‚")
        return
    
    # æ˜¾ç¤ºåˆ†æç»“æœ
    if analysis_type == "æŒç»­æ€§çƒ­ç‚¹":
        st.markdown("#### ğŸ”¥ æŒç»­æ€§çƒ­ç‚¹æ’è¡Œæ¦œ")
        if persistence_fig:
            st.plotly_chart(persistence_fig, use_container_width=True)
        else:
            st.info("æ²¡æœ‰æ‰¾åˆ°æŒç»­æ€§çƒ­ç‚¹")
        
        # æ˜¾ç¤ºæ—¶é—´åºåˆ—è¶‹åŠ¿
        if timeline_fig:
            st.markdown("#### ğŸ“ˆ çƒ­ç‚¹ç»„åˆå¼ºåº¦å˜åŒ–")
            st.plotly_chart(timeline_fig, use_container_width=True)
    
    elif analysis_type == "è½®åŠ¨åˆ†æ":
        st.markdown("#### ğŸ”„ æ¿å—è½®åŠ¨åˆ†æ")
        industry_fig, concept_fig = create_sector_rotation_chart(temporal_df)
        
        if industry_fig:
            st.plotly_chart(industry_fig, use_container_width=True)
        if concept_fig:
            st.plotly_chart(concept_fig, use_container_width=True)
    
    elif analysis_type == "æ—¶é—´åºåˆ—çƒ­åŠ›å›¾":
        st.markdown("#### ğŸ“… æ—¶é—´åºåˆ—çƒ­åŠ›å›¾")
        if heatmap_fig:
            st.plotly_chart(heatmap_fig, use_container_width=True)
        else:
            st.info("æ— æ³•ç”Ÿæˆæ—¶é—´åºåˆ—çƒ­åŠ›å›¾")
    
    # æ˜¾ç¤ºåŸå§‹æ•°æ®
    with st.expander("ğŸ“Š æŸ¥çœ‹è¯¦ç»†æ•°æ®"):
        st.dataframe(temporal_df, use_container_width=True)
        
        # ç»Ÿè®¡ä¿¡æ¯
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("æ€»è®°å½•æ•°", len(temporal_df))
        with col2:
            st.metric("ç‹¬ç‰¹ç»„åˆæ•°", temporal_df['industry_concept'].nunique())
        with col3:
            avg_strength = temporal_df['strength'].mean()
            st.metric("å¹³å‡å¼ºåº¦", f"{avg_strength:.2f}")

def show_hotspot_scan(df, uploaded_file, load_data_with_cache):
    """æ˜¾ç¤ºçƒ­ç‚¹æ‰«æåŠŸèƒ½ - å®Œæ•´ç‰ˆæœ¬ï¼ˆåŒ…å«ä¸¤ä¸ªé˜¶æ®µï¼‰"""
    
    st.markdown(
        '<div style="color: #ff6b00 !important; font-size: 18px; font-weight: bold; margin-bottom: 20px;">ğŸ“Š çƒ­ç‚¹æ‰«æä¸æ—¶é—´åºåˆ—åˆ†æ</div>',
        unsafe_allow_html=True
    )

    # è®¾ç½®æ˜¾ç¤ºçš„äº¤æ˜“å¤©æ•°
    col1, col2 = st.columns([1, 3])
    with col1:
        display_days = st.selectbox("æ˜¾ç¤ºå¤©æ•°", [5, 10, 15, 20, 30], index=1, key="hotspot_days")

    # é‡æ–°åŠ è½½åŸå§‹æ•°æ®
    with st.spinner("åŠ è½½å®Œæ•´æ•°æ®ä¸­..."):
        raw_df = load_data_with_cache(uploaded_file)
        raw_df = data_processing.filter_non_trading_days(raw_df)
        raw_df = data_processing.validate_and_clean_data(raw_df)

    # ç¡®ä¿æ•°æ®æŒ‰æ—¥æœŸæ’åº
    if 'æ—¥æœŸ' in raw_df.columns:
        df_sorted = raw_df.sort_values('æ—¥æœŸ').copy()
    else:
        df_sorted = raw_df.copy()

    # è·å–æœ€è¿‘çš„æ•°æ®å¹¶æŒ‰æ—¥æœŸå€’åº
    recent_df = df_sorted.tail(display_days).copy()
    if 'æ—¥æœŸ' in recent_df.columns:
        recent_df = recent_df.sort_values('æ—¥æœŸ', ascending=False)
    else:
        recent_df = recent_df.sort_index(ascending=False)

    # åˆ›å»ºä¸»é€‰é¡¹å¡ï¼šå•æ—¥åˆ†æ vs æ—¶é—´åºåˆ—åˆ†æ
    tab1, tab2 = st.tabs(["ğŸ“… å•æ—¥çƒ­ç‚¹åˆ†æ", "ğŸ“ˆ æ—¶é—´åºåˆ—åˆ†æ"])

    with tab1:
        show_daily_analysis(recent_df)

    with tab2:
        show_temporal_analysis(recent_df, display_days)